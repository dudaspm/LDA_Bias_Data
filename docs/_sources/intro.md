# Introduction to the Notebook

```{note}
To reviewers - we are utilizing Jupyter Books {cite:p}`executable_books_community_2020` for our development. We did not have any part in the development of Jupyter Books (but we sure do thank them), but our contribution is the content contained in this notebook. 

Also, because of the nature of the resource and making this available as an accessible resource. We were not sure how to completely anonymous the submission. We did try our best to do so.
```

Welcome to our introduction and application of latent dirichlet allocation or LDA {cite:p}`blei2003latent`. Our hope with this notebook is to discuss LDA in such a way as to make it approachable as a machine learning technique. From "when to use LDA" to "applying LDA to talk about bias," we tried our best to cover the topic in an approachable manner. If we are missing anything, feel free to click on the <img src="https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png" alt="GitHub Logo" style="display: inline-block;width: 20px;height: 20px;"> button at the top-right side of the page. 

## Chapters

> *Notebook Introduction* - Provides details on how to run this Jupyter Notebook in Binder, Google Colab, or even in the browser itself. 

> *Latent Dirichlet Allocation (LDA)* - Introduces the topic modeling and LDA. Including an example of its application using Python

> *Dirichlet Distribution* - We provide a look at the Dirichlet Distribution using The Chinese Restaurant Process to illistrate how it is derived and used in LDA. 

> *Jigsaw - an Implementation of LDA* - We wanted to provide a use-case for LDA, so we coupled LDA and Unintended Bias (a dataset from Kaggle)

> *Visualizing and Anayzing Jigsaw* - 

## References 

I know it is tradition to have references at the end of books, but when you are standing on the shoulders of giants. You thank them first.

```{bibliography} 
```